{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第四章：训练模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前几章讨论的几个模型都不知道具体的实施细节。\n",
    "\n",
    "* 一：这一章，将从**线性回归模型**开始。介绍两种非常不同的训练模型的方法。  \n",
    "    * 1、通过“闭式”方程——直接计算出最适合训练集的模型参数（也就是使训练集上的成本函数最小化的模型参数）  \n",
    "    * 2、使用迭代优化的方法，即梯度下降（`GD`），逐渐调整模型参数直至训练集上的成本函数调至最低，最终趋同于第一种方法计算出来的模型参数。也会研究几个梯度下降的变体，包括批量梯度下降、小批量梯度下降以及随机梯度下降。  \n",
    "\n",
    "* 二：进行多项式回归的讨论，这是一个更为复杂的模型，更适合非线性数据集。由于该模型的参数比线性模型更多，因此更容易造成对训练数据过度拟合，我们将使用学习曲线来分辨这种情况是否发生，然后再介绍几种正则化方法，降低过度拟合训练数据的风险。\n",
    "\n",
    "* 三：学习两种经常用于分类任务的模型：`Logistic`回归和`Softmax`回归。\n",
    "\n",
    "了解这些系统如何工作非常有帮助。针对你的任务，它有助于快速定位到合适的模型，正确的训练算法，以及一套适当的超参数。不仅如此，后期还能更高效的执行错误调试和错误分析。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备工作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "# CHAPTER_ID = \"classification\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\") # , CHAPTER_ID\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "# 存图片时，要先存（save_fig），再展示（show）\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 线性回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在第1章中，学过一个简单的生活满意度的回归模型：life_satisfaction=$\\theta_{0}+\\theta_{1} \\times G D P_{-}$ per capita.\n",
    "\n",
    "这个模型就是输入特征`GDP_per_capita`的线性函数，$\\theta_{0}$和$\\theta_{1}$是模型的参数。  \n",
    "更为概括的说，线性模型就是对输入特征加权求和，再加上一个偏置项（也称为截距项）的常数。  \n",
    "公式如下：  \n",
    "<center>$\\hat{y}=\\theta_{0}+\\theta_{1} x_{1}+\\theta_{2} x_{2}+\\cdots+\\theta_{n} x_{n}$</center>\n",
    "\n",
    "* $\\hat{y}$是预测值  \n",
    "\n",
    "* $n$是特征的数量  \n",
    "\n",
    "* $x_{\\mathrm{i}}$是第$i$个特征值\n",
    "\n",
    "* $\\theta_{j}$是第$j$个模型参数（包括偏执项$\\theta_{0}$以及特征权重$\\theta_{1}$,$\\theta_{2}$,···,$\\theta_{n}$）\n",
    "\n",
    "这也可以用更为简单的向量化形式表达，公式如下：  \n",
    "<center>$\\hat{y}=h_{\\theta}(\\mathbf{x})=\\theta^{T} \\cdot \\mathbf{x}$</center>\n",
    "\n",
    "* $\\theta$是模型的参数向量，包括偏置项$\\theta_{0}$以及特征权重$\\theta_{1}$到$\\theta_{n}$\n",
    "\n",
    "* $\\theta^{T}$是$\\theta$的转置向量\n",
    "\n",
    "* $\\mathbf{X}$是实例的特征向量，包括从$x_{0}$到$x_{n}$，$x_{0}$永远为1\n",
    "\n",
    "* $\\theta^{T} \\cdot \\mathbf{x}$是$\\theta^{T}$和$\\mathbf{X}$的点积\n",
    "\n",
    "* $h_{\\theta}$是使用模型参数$\\theta$的假设函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练模型就是设置模型参数直到模型最适应训练集的过程。要达到这个目的，首先需要知道怎么衡量模型对训练数据的拟合程度是好还是差。在第2章中，我们了解到回归模型最常见的性能指标是均方根误差（`RMSE`）。因此，在训练线性回归模型时，需要找到最小化`RMSE`的$\\theta$值，在实践中，将均方误差（`MSE`）最小化比最小化`RMSE`更为简单，二者效果相同（因为使函数最小化的值，同样也使其平方根最小。）<sup>注1</sup>\n",
    "\n",
    "在训练集$\\mathbf{X}$上，使用如下公式计算线性回归的`MSE`，$h_{\\theta}$为假设函数  \n",
    "<center>$\\operatorname{MSE}\\left(\\mathbf{X}, h_{\\theta}\\right)=\\frac{1}{m} \\sum_{i=1}^{m}\\left(\\theta^{T} \\cdot \\mathbf{x}^{(i)}-y^{(i)}\\right)^{2}$</center>\n",
    "\n",
    "注1：通常情况下，学习算法优化的函数都与评估最终模型时使用的性能指标函数不同。这可能是1、前者更容易计算；2、前者具有某些后者缺乏的差异属性；3、想在训练期间约束模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 标准方程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "提供一个闭式解方法（直接得出结果的数学方程--标准方程）\n",
    "\n",
    "<center>$\\widehat{\\theta}=\\left(X^{T} \\cdot X\\right)^{-1} \\cdot X^{T} \\cdot \\mathrm{y}$</center>\n",
    "\n",
    "* $\\widehat{\\theta}$是使成本函数最小的${\\theta}$值\n",
    "* $y$是包含$y^{(1)}$到$y^{(m)}$的目标值向量\n",
    "\n",
    "生成一些线性数据来测试这个公式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.91815549],\n",
       "       [3.08762271]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "X = 2 * np.random.rand(100, 1)\n",
    "y = 4 + 3 * X + np.random.randn(100, 1)\n",
    "\n",
    "# 接下来计算theta_hat，使用np.linalg中的inv()函数来对矩阵求逆，并用dot()方法计算矩阵的内积\n",
    "X_b = np.c_[np.ones((100, 1)), X]\n",
    "theta_best = np.linalg.inv(X_b.T.dot(X_b)).dot(X_b.T).dot(y)\n",
    "theta_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用来生成数据的函数是$y=4+3x_{0}+高斯噪声$，期望得到的${\\theta_{0}}=4$，${\\theta_{1}}=3$，实际得到的结果是${\\theta_{0}}=3.815$，${\\theta_{1}}=3.184$。这两个结果非常接近（因为存在高斯噪声的缘故不可能完全一样）。\n",
    "\n",
    "下面用$\\widehat{\\theta}$做预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.91815549],\n",
       "       [10.09340091]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = np.array([[0], [2]])\n",
    "X_new_b = np.c_[np.ones((2, 1)), X_new]\n",
    "y_predict = X_new_b.dot(theta_best)\n",
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figure 预测随机生成的线性数据\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 绘制模型的预测情况\n",
    "plt.plot(X_new, y_predict, \"r-\")\n",
    "plt.plot(X, y, \"b.\")\n",
    "plt.axis([0, 2, 0, 15])\n",
    "save_fig(\"预测随机生成的线性数据\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3.91815549]), array([[3.08762271]]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scikit-Learn 的等效代码：\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X, y)\n",
    "lin_reg.intercept_, lin_reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.91815549],\n",
       "       [10.09340091]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算复杂度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "标准方程的计算复杂度通常为$O(n^{2.4})$到$O(n^{3})$之间。所以，当特征向量翻倍时，计算时间大约在$2^{2.4}=5.3$到$2^{3}=8$倍之间。\n",
    "\n",
    "好的一方面是，对于训练集中的实例数量来说，方程是线性的，所以能够有效地处理大量的训练集（只要内存足够）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，看几个适合特征数或者训练实例数量大到内存无法满足要求时的模型训练方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 梯度下降"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "梯度下降能够为大范围的问题找到最优解：通过测量参数向量${\\theta}$相关的误差函数的局部梯度，并不断沿着降低梯度的方向调整，直到梯度降为0，到达最小值。\n",
    "\n",
    "具体来说，首先使用一个随机的${\\theta}$值（随机初始化），然后逐步改进，每次踏出一步，每一步都尝试降低一点成本函数，知道算法收敛出一个最小值。\n",
    "<img src=\"./images/Book/梯度下降.jpg\" width=\"50%\" height=\"50%\"></img>\n",
    "\n",
    "**存在的问题：**\n",
    "* 当学习率太低时，算法需要经过大量迭代才能收敛，将耗费很长时间\n",
    "* 如果学习率太高，会导致算法发散，值越来越大。\n",
    "* 并不是所有的成本函数都像一个漂亮的碗，不同形状的成本函数会收敛到一个局部最小值而不是全局最小值。\n",
    "\n",
    "    幸好，线性回归模型的成本函数恰好是一个凸函数，也就是说不存在局部最小，只有一个全局最小值。同时他也是一个连续函数，所以斜率不会产生陡峭的变化。**结论**：即便是乱走，梯度下降都可以趋近到全局最小值。\n",
    "* 成本函数虽然是碗状的，但如果不同特征的尺寸差别巨大，那它可能是一个非常细小的碗，这将导致收敛缓慢。**所以要保证所有特征值的大小比例都差不多**\n",
    "* 模型的参数越多，这个空间的维度就越多，搜索就越难。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 批量梯度下降"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
